---
title: "CC Modeling"
author: "Chris Joyce"
date: "2025"
output: 
  html_document:
    number_sections: false
    toc: true
    toc_depth: 2
editor_options:
  chunk_output_type: inline
---

# Objective

### This notebook focuses on applying different modeling methods to find interesting relationships between customers and their ordering habits.  Specifically, we utilize unsupervised methods such as clustering to seek out common characteristics for customers who tend to have similar order patterns, and apply these methods based on monthly and yearly order totals.  We continue to emphasize the two customer groups of interest, gallon-only Local Market Partners, and all customers, created in the EDA notebook.


# Load in and prep


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
library(skimr)
library(tableone)
library(forecast)
library(tseries)
library(astsa)
library(xts)
library(C50)
library(tidymodels)
library(xgboost)
library(caret)
library(future)
library(lubridate)
library(clustMixType)
library(cluster)
library(dbscan)
library(sf)
library(maps)
library(mclust)
plan(multisession, workers = 6)
```

```{r, warning = FALSE}
setwd("F:/Lori/Downloads")
m <- read.csv('merged_data.csv')
```

```{r}
# Type casting character variables into factors, and binary variables as logical
m_chrs <- m[, c(5, 13, 16, 17, 18)]
m_chrs <- lapply(m_chrs, as.factor)
m_chrs <- as.data.frame(m_chrs)

m[, c(5, 13, 16, 17, 18)] <- m_chrs

m_log <- m[, c(19, 20)]
m_log <- lapply(m_log, as.logical)
m_log <- as.data.frame(m_log)

m[, c(19, 20)] <- m_log

m <- m |>
  mutate(Has.Primary.Group.Number. = as.factor(Has.Primary.Group.Number.))
```

```{r}
m <- m %>%
  separate(full.address, into = c("zip", "city", "state", "state_abbr", "county", "county_code", "longitude", "latitude"), sep = ",")
```

```{r}
# Separating latitude and longitude data from address column
m <- m %>%
  mutate(coordinates = paste(latitude, longitude, sep = ","))

m$latitude <- as.numeric(m$latitude)
m$longitude <- as.numeric(m$longitude)
```

```{r}
#str(m)
#summary(m)
```

```{r}
# LMP group
LMP_distinct <- m |>
  filter(LOCAL_MARKET_PARTNER == TRUE, CO2_CUSTOMER == FALSE, ORDERED_CASES == 0, LOADED_CASES == 0, DELIVERED_CASES == 0)
  #summarize(case_avg = mean(ORDERED_CASES), gallon_avg = mean(ORDERED_GALLONS), total_avg = case_avg + gallon_avg) |>
  #arrange(case_avg)
head(LMP_distinct)
```

```{r}
# Aggregate yearly order data for LMP customer group
g1_y <- LMP_distinct %>%
  group_by(CUSTOMER_NUMBER, YEAR) %>%
  summarise(TOTAL_YEAR_ORDERS = sum(ORDERED_CASES + ORDERED_GALLONS, na.rm = TRUE),
            LATITUDE = first(latitude),
            LONGITUDE = first(longitude),
            PRIMARY_GROUP_NUMBER = first(PRIMARY_GROUP_NUMBER),
            LOCAL_MARKET_PARTNER = first(LOCAL_MARKET_PARTNER),
            FREQUENT_ORDER_TYPE = first(FREQUENT_ORDER_TYPE),
            COLD_DRINK_CHANNEL = first(COLD_DRINK_CHANNEL),
            TRADE_CHANNEL = first(TRADE_CHANNEL),
            SUB_TRADE_CHANNEL = first(SUB_TRADE_CHANNEL),
            TRANSACTION_DATE = first(TRANSACTION_DATE),
            Month = first(Month),
            Has.Primary.Group.Number. = first(Has.Primary.Group.Number.),
            .groups = 'drop') %>%
  ungroup()

head(g1_y)

```

```{r}
# Aggregated orders for each year (all customers)
g2_y <- m |>
  select(CUSTOMER_NUMBER, zip, PRIMARY_GROUP_NUMBER, LOCAL_MARKET_PARTNER, CO2_CUSTOMER, FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, TRANSACTION_DATE, ORDERED_CASES, ORDERED_GALLONS, Month, Has.Primary.Group.Number., YEAR,
         latitude, longitude) |>
  group_by(CUSTOMER_NUMBER, YEAR) |>
  summarise(TOTAL_YEAR_ORDERS = sum(ORDERED_CASES + ORDERED_GALLONS, na.rm = TRUE),
            LATITUDE = first(latitude),
            LONGITUDE = first(longitude),
            PRIMARY_GROUP_NUMBER = first(PRIMARY_GROUP_NUMBER),
            LOCAL_MARKET_PARTNER = first(LOCAL_MARKET_PARTNER),
            CO2_CUSTOMER = first(CO2_CUSTOMER),
            FREQUENT_ORDER_TYPE = first(FREQUENT_ORDER_TYPE),
            COLD_DRINK_CHANNEL = first(COLD_DRINK_CHANNEL),
            TRADE_CHANNEL = first(TRADE_CHANNEL),
            SUB_TRADE_CHANNEL = first(SUB_TRADE_CHANNEL),
            TRANSACTION_DATE = first(TRANSACTION_DATE),
            Month = first(Month),
            Has.Primary.Group.Number. = first(Has.Primary.Group.Number.),
            .groups = 'drop') |>
  ungroup()

head(g2_y)
```

```{r}
# Aggregate monthly orders for all customers
g2_m <- m |>
  group_by(Month, CUSTOMER_NUMBER) |>
  summarise(ORDERED_GALLONS = sum(ORDERED_GALLONS, na.rm = TRUE),
            ORDERED_CASES = sum(ORDERED_CASES, na.rm = TRUE),
            MONTHLY_TOTAL = sum(ORDERED_GALLONS + ORDERED_CASES, na.rm = TRUE),
            zip = first(zip),
            PRIMARY_GROUP_NUMBER = first(PRIMARY_GROUP_NUMBER),
            LOCAL_MARKET_PARTNER = first(LOCAL_MARKET_PARTNER),
            CO2_CUSTOMER = first(CO2_CUSTOMER),
            FREQUENT_ORDER_TYPE = first(FREQUENT_ORDER_TYPE),
            COLD_DRINK_CHANNEL = first(COLD_DRINK_CHANNEL),
            TRADE_CHANNEL = first(TRADE_CHANNEL),
            SUB_TRADE_CHANNEL = first(SUB_TRADE_CHANNEL),
            TRANSACTION_DATE = first(TRANSACTION_DATE),
            Has.Primary.Group.Number. = first(Has.Primary.Group.Number.),
            YEAR = first(YEAR),
            .groups = 'drop') |>
  ungroup()
```

```{r}
# Aggregate monthly gallon orders for LMP group
g1_m <- LMP_distinct |>
  group_by(Month, CUSTOMER_NUMBER) |>
  summarise(ORDERED_GALLONS = sum(ORDERED_GALLONS, na.rm = TRUE),
            zip = first(zip),
            PRIMARY_GROUP_NUMBER = first(PRIMARY_GROUP_NUMBER),
            FREQUENT_ORDER_TYPE = first(FREQUENT_ORDER_TYPE),
            COLD_DRINK_CHANNEL = first(COLD_DRINK_CHANNEL),
            TRADE_CHANNEL = first(TRADE_CHANNEL),
            SUB_TRADE_CHANNEL = first(SUB_TRADE_CHANNEL),
            TRANSACTION_DATE = first(TRANSACTION_DATE),
            Has.Primary.Group.Number. = first(Has.Primary.Group.Number.),
            YEAR = first(YEAR),
            .groups = 'drop') |>
  ungroup()
```

```{r}
head(g1_m)
```

# Supplemental EDA


```{r}
# Average yearly orders for each trade channel (LMP group)
g1_y |>
  select(TOTAL_YEAR_ORDERS, TRADE_CHANNEL) |>
  group_by(TRADE_CHANNEL) |>
  summarise(y_avg = mean(TOTAL_YEAR_ORDERS, na.rm = TRUE),
            .groups = 'drop') |>
  arrange(desc(y_avg))
```

```{r}
# Average yearly orders for each trade channel (all customers)
g2_y |>
  select(TOTAL_YEAR_ORDERS, TRADE_CHANNEL) |>
  group_by(TRADE_CHANNEL) |>
  summarise(y_avg = mean(TOTAL_YEAR_ORDERS, na.rm = TRUE),
            .groups = 'drop') |>
  arrange(desc(y_avg))
```

```{r}
# Average monthly orders for each trade channel (LMP group)
g1_m |>
  select(ORDERED_GALLONS, TRADE_CHANNEL) |>
  group_by(TRADE_CHANNEL) |>
  summarise(m_avg = mean(ORDERED_GALLONS, na.rm = TRUE),
            .groups = 'drop') |>
  arrange(desc(m_avg))
```

```{r}
# Average monthly orders for each trade channel (all customers)
g2_m |>
  select(MONTHLY_TOTAL, TRADE_CHANNEL) |>
  group_by(TRADE_CHANNEL) |>
  summarise(m_avg = mean(MONTHLY_TOTAL, na.rm = TRUE),
            .groups = 'drop') |>
  arrange(desc(m_avg))
```



```{r}
# Calculate percentiles for TOTAL_YEAR_ORDERS
g1_y_percentiles <- quantile(g1_y$TOTAL_YEAR_ORDERS, probs = seq(0, 1, 0.01), na.rm = TRUE)

# View the percentiles
g1_y_percentiles
```

```{r}
g2_y_percentiles <- quantile(g2_y$TOTAL_YEAR_ORDERS, probs = seq(0, 1, 0.01), na.rm = TRUE)

g2_y_percentiles
```

```{r}
# Calculate percentiles for monthly orders
g1_m_percentiles <- quantile(g1_m$ORDERED_GALLONS, probs = seq(0, 1, 0.01), na.rm = TRUE)

g1_m_percentiles
```

```{r}
g2_m_percentiles <- quantile(g2_m$MONTHLY_TOTAL, probs = seq(0, 1, 0.01), na.rm = TRUE)

g2_m_percentiles
```

### We note the percentiles for yearly orders for customers in group 1 (LMP gallon only) and group 2 (all customers).  83.5% of customers in group 1 are below the existing 400 gallon per year threshold.  72% of customers in group 2 are below this threshold.

```{r}
# Extend the Month column
#g1_m <- g1_m |>
  #mutate(Month = ifelse(YEAR == 2023, Month, Month + 12))

# Sort the data by CUSTOMER_NUMBER and Extended_Month
#g1_m <- g1_m |>
  #arrange(Month)

#g1_m
```

```{r}
# Calculating growth index for LMP group with orders between  7.5 - 33.3 gals/month

# Sort the data by CUSTOMER_NUMBER, YEAR, and Month
g1_m_agi <- g1_m |>
  filter(ORDERED_GALLONS >= 7.5 & ORDERED_GALLONS <= 33.3) |>
  arrange(CUSTOMER_NUMBER, YEAR, Month)

# Calculate the month-by-month growth index as a percentage
g1_m_agi <- g1_m_agi |>
  group_by(CUSTOMER_NUMBER, YEAR) |>
  mutate(Previous_Month_Total = lag(ORDERED_GALLONS),
         Growth_Index = ifelse(Previous_Month_Total == 0, NA, (ORDERED_GALLONS - Previous_Month_Total) / Previous_Month_Total * 100)) |>
  ungroup()

# Handle NA values in Growth_Index
g1_m_agi <- g1_m_agi |>
  mutate(Growth_Index = ifelse(is.na(Growth_Index), 0, Growth_Index))

# Calculate the average monthly growth index for each customer for each year
average_growth_index <- g1_m_agi |>
  group_by(CUSTOMER_NUMBER, YEAR) |>
  summarise(Average_Growth_Index = mean(Growth_Index, na.rm = TRUE),
            .groups = 'drop')

# Select relevant columns and join the average growth index
g1_m_agi <- g1_m_agi |>
  select(CUSTOMER_NUMBER, zip, PRIMARY_GROUP_NUMBER, FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, Has.Primary.Group.Number., YEAR) |>
  distinct(CUSTOMER_NUMBER, YEAR, .keep_all = TRUE) |>
  left_join(average_growth_index, by = c("CUSTOMER_NUMBER", "YEAR")) |>
  arrange(desc(Average_Growth_Index))

g1_m_agi <- g1_m_agi |>
  mutate(AGI_GROUP = ifelse(Average_Growth_Index < 0, 0,
                            ifelse(Average_Growth_Index >= 5.5 & Average_Growth_Index <= 79, 1, NA)))
```

```{r}
# Calculating growth index for all customers with orders between 7.5 - 33.3 gals/month

# Sort the data by CUSTOMER_NUMBER, YEAR, and Month
g2_m_agi <- g2_m |>
  filter(ORDERED_GALLONS >= 7.5 & ORDERED_GALLONS <= 33.3) |>
  arrange(CUSTOMER_NUMBER, YEAR, Month)

# Calculate the month-by-month growth index as a percentage
g2_m_agi <- g2_m_agi |>
  group_by(CUSTOMER_NUMBER, YEAR) |>
  mutate(Previous_Month_Total = lag(MONTHLY_TOTAL),
         Growth_Index = ifelse(Previous_Month_Total == 0, NA, (MONTHLY_TOTAL - Previous_Month_Total) / Previous_Month_Total * 100)) |>
  ungroup()

# Handle NA values in Growth_Index (e.g., first month for each customer)
g2_m_agi <- g2_m_agi |>
  mutate(Growth_Index = ifelse(is.na(Growth_Index), 0, Growth_Index))

# Calculate the average monthly growth index for each customer for each year
average_growth_index <- g2_m_agi |>
  group_by(CUSTOMER_NUMBER, YEAR) |>
  summarise(Average_Growth_Index = mean(Growth_Index, na.rm = TRUE),
            .groups = 'drop')

# Select relevant columns and join the average growth index
g2_m_agi <- g2_m_agi |>
  select(CUSTOMER_NUMBER, zip, PRIMARY_GROUP_NUMBER, FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, Has.Primary.Group.Number., YEAR) |>
  distinct(CUSTOMER_NUMBER, YEAR, .keep_all = TRUE) |>
  left_join(average_growth_index, by = c("CUSTOMER_NUMBER", "YEAR")) |>
  arrange(desc(Average_Growth_Index))

g2_m_agi <- g2_m_agi |>
  mutate(AGI_GROUP = ifelse(Average_Growth_Index < 0, 0,
                            ifelse(Average_Growth_Index >= 5.5 & Average_Growth_Index <= 79, 1, NA)))
```

```{r}
# Merge based on 'customer_number'
g1_y <- merge(g1_y, g1_m_agi[, c('CUSTOMER_NUMBER', 'AGI_GROUP')], by = 'CUSTOMER_NUMBER', all.x = TRUE)

names(g1_y)[names(g1_y) == "AGI_GROUP.x"] <- "AGI_GROUP"
names(g1_y)[names(g1_y) == "AGI_GROUP.y"] <- "AGI_GROUP"
head(g1_y)
```


```{r}

# Merge based on 'customer_number'
g2_y <- merge(g2_y, g2_m_agi[, c('CUSTOMER_NUMBER', 'AGI_GROUP')], by = 'CUSTOMER_NUMBER', all.x = TRUE)

names(g2_y)[names(g2_y) == "AGI_GROUP.x"] <- "AGI_GROUP"
names(g2_y)[names(g2_y) == "AGI_GROUP.y"] <- "AGI_GROUP"
head(g2_y)
```


```{r}
g1_m_agi_percentiles <- quantile(g1_m_agi$Average_Growth_Index, probs = seq(0, 1, 0.01), na.rm = TRUE)

g1_m_agi_percentiles
```

```{r}
g2_m_agi_percentiles <- quantile(g2_m_agi$Average_Growth_Index, probs = seq(0, 1, 0.01), na.rm = TRUE)

g2_m_agi_percentiles
```

### We calculate percentiles of growth index values for the aforementioned groups.  30% of customers in group 1 show promising month by month growth (5.5 - 79%).  34% of customers in group 2 show between 6% and 96% month by month growth.  Thus, we will focus on these specific customers who show consistent positive growth and assign them binary values to indicate positive or negative growth.  Note that these monthly order percentiles are exclusively for customers who are below the existing 400 gallon per year threshold across both groups.

```{r}
# Assigning AGI group values based on monthly growth index
g1_m_agi <- g1_m_agi %>%
  mutate(AGI_GROUP = ifelse(Average_Growth_Index < 0, 0,
                            ifelse(Average_Growth_Index >= 5.5 & Average_Growth_Index <= 79, 1, NA))) # 0 for declining AGI, 1 for low-medium AGI, NA for customers greatly surpassing threshold

g2_m_agi <- g2_m_agi |>
  mutate(AGI_GROUP = ifelse(Average_Growth_Index < 0, 0,
                            ifelse(Average_Growth_Index >= 6  & Average_Growth_Index <= 96, 1, NA)))
```

# K - Prototype Clustering for Customers Ordering Within 400 gallons/year

```{r}
# Cluster for LMP within threshold
g1_m_cluster_1 <- g1_m_agi |>
  select(FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, AGI_GROUP, Average_Growth_Index) |>
  filter(AGI_GROUP == 1)

# Scale numerical variables using min-max scaling
#g1_m_cluster_1 <- g1_m_cluster_1 |>
  #mutate(Average_Growth_Index = (Average_Growth_Index - min(Average_Growth_Index)) / (max(Average_Growth_Index) - min(Average_Growth_Index)))
```


```{r}
# Calculate WCSS for different numbers of clusters
set.seed(22)
wcss <- numeric(15)
for (k in 1:15) {
  kpres <- kproto(g1_m_cluster_1, k)
  wcss[k] <- kpres$tot.withinss
}

# Plot the Elbow graph
plot(1:15, wcss, type = "b", xlab = "Number of Clusters", ylab = "Within-cluster Sum of Squares")
```


```{r}
set.seed(22)

kpres <- kproto(g1_m_cluster_1, k = 7)  # Adjust 'k' to the desired number of clusters

summary(kpres)

g1_m_cluster_1$Cluster <- kpres$cluster
```

```{r}
#g1mc1_summary_output <- capture.output(summary(kpres))

#writeLines(g1mc1_summary_output, "g1mc1_cluster_summary.txt")
```

```{r}
# Create boxplot
#ggplot(g1_m_cluster, aes(x = factor(Cluster), y = Average_Growth_Index)) +
  #geom_boxplot() +
  #labs(x = "Cluster Number", y = "AGI") +
  #theme_minimal()
```

```{r}
#ggplot(g1_m_cluster, aes(x = FREQUENT_ORDER_TYPE, y = Average_Growth_Index, color = factor(Cluster))) +
  #geom_point() +
  #labs(x = "FREQUENT_ORDER_TYPE", y = "AGI", color = "Cluster") +
  #theme_minimal()
```

```{r}
# Cluster for LMP within threshold, AGI < 0
g1_m_cluster_0 <- g1_m_agi |>
  select(FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL, Has.Primary.Group.Number.,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, AGI_GROUP, Average_Growth_Index) |>
  filter(AGI_GROUP == 0)

# Scale numerical variables using min-max scaling
#g1_m_cluster_0 <- g1_m_cluster_0 |>
  #mutate(Average_Growth_Index = (Average_Growth_Index - min(Average_Growth_Index)) / (max(Average_Growth_Index) - min(Average_Growth_Index)))
```

```{r}
# Calculate WCSS for different numbers of clusters
wcss <- numeric(15)
for (k in 1:15) {
  kpres <- kproto(g1_m_cluster_0, k)
  wcss[k] <- kpres$tot.withinss
}

# Plot the Elbow graph
plot(1:15, wcss, type = "b", xlab = "Number of Clusters", ylab = "Within-cluster Sum of Squares")
```

```{r}
set.seed(22)

kpres <- kproto(g1_m_cluster_0, k = 9)  # Adjust 'k' to the desired number of clusters

summary(kpres)

g1_m_cluster_0$Cluster <- kpres$cluster
```

```{r}
# Write cluster outputs to text file
#summary_output_g1mc_0 <- capture.output(summary(kpres))


#writeLines(summary_output, "cluster_summary_g1m_0.txt")

# View the first few rows of the data frame
#head(g1_m_cluster)
```

```{r}
# Cluster for all customers within threshold and AGI = 1
g2_m_cluster_1 <- g2_m_agi |>
  select(FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL, Has.Primary.Group.Number.,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, AGI_GROUP, Average_Growth_Index) |>
  filter(AGI_GROUP == 1)

# Scale numerical variables using min-max scaling
#g2_m_cluster <- g2_m_cluster |>
  #mutate(Average_Growth_Index = (Average_Growth_Index - min(Average_Growth_Index)) / (max(Average_Growth_Index) - min(Average_Growth_Index)))
```

```{r}
# Calculate WCSS for different numbers of clusters
wcss <- numeric(15)
for (k in 1:15) {
  kpres <- kproto(g2_m_cluster_1, k)
  wcss[k] <- kpres$tot.withinss
}

# Plot the Elbow graph
plot(1:15, wcss, type = "b", xlab = "Number of Clusters", ylab = "Within-cluster Sum of Squares")
```

```{r}
kpres <- kproto(g2_m_cluster_1, k = 8)  # Adjust 'k' to the desired number of clusters

summary(kpres)

g2_m_cluster_1$Cluster <- kpres$cluster
```

```{r}
summary_output_g2mc_1 <- capture.output(summary(kpres))


writeLines(summary_output_g2mc_1, "cluster_summary_g2m_1.txt")

# View the first few rows of the data frame
#head(g1_m_cluster)
```

```{r}
# Create boxplot
#ggplot(g2_m_cluster, aes(x = factor(Cluster), y = Average_Growth_Index)) +
  #geom_boxplot() +
  #labs(x = "Cluster Number", y = "AGI") +
  #theme_minimal()
```

```{r}
#ggplot(g2_m_cluster, aes(x = FREQUENT_ORDER_TYPE, y = Average_Growth_Index, color = factor(Cluster))) +
  #geom_point() +
  #labs(x = "FREQUENT_ORDER_TYPE", y = "AGI", color = "Cluster") +
  #theme_minimal()
```

```{r}
# Cluster for all within threshold and AGI < 0
g2_m_cluster_0<- g2_m_agi |>
  select(FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL, Has.Primary.Group.Number.,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, AGI_GROUP, Average_Growth_Index) |>
  filter(AGI_GROUP == 0)

# Scale numerical variables using min-max scaling
#g2_m_cluster <- g2_m_cluster |>
  #mutate(Average_Growth_Index = (Average_Growth_Index - min(Average_Growth_Index)) / (max(Average_Growth_Index) - min(Average_Growth_Index)))
```

```{r}
# Calculate WCSS for different numbers of clusters
wcss <- numeric(15)
for (k in 1:15) {
  kpres <- kproto(g2_m_cluster_0, k)
  wcss[k] <- kpres$tot.withinss
}

# Plot the Elbow graph
plot(1:15, wcss, type = "b", xlab = "Number of Clusters", ylab = "Within-cluster Sum of Squares")
```

```{r}
kpres <- kproto(g2_m_cluster_0, k = 7)  # Adjust 'k' to the desired number of clusters

summary(kpres)

g2_m_cluster_0$Cluster <- kpres$cluster
```

```{r}
#summary_output_g2mc_0 <- capture.output(summary(kpres))


#writeLines(summary_output_g2mc_0, "cluster_summary_g2m_0.txt")

# View the first few rows of the data frame
#head(g1_m_cluster)
```


## Within Threshold Cluster Analysis
#### For the sake of simplicity, we will only mention the channels/order types for which the highest proportion of customers belong to, for both this analysis and analysis of clusters for customers beyond the threshold.

### Clusters for LMP gallon-only customers with positive growth (AGI Group = 1)
#### Clusters 1 and 5 have the highest mean AGI values (37% and 56%).  We will emphasize these clusters in terms of their customer demographics as our "strong performers".  In other words, these are customers who should be considered for onboarding to red truck service.  Although they are currently below the 400 gallon yearly threshold, they show strong month-by-month order growth, and will likely surpass this threshold in the future.  This interpretation is applicable to further analysis of clusters within this AGI group.
#### Frequent Order Type Proportions: For cluster 1, ~70% of customers place orders through sales representatives.  For cluster 5, ~73% of customers also place orders through sales reps.
#### Cold Drink Channel Proportions: For cluster 1, 91% of customers are within the event channel.  For cluster 5, ~81% of customers are also within the event channel.
#### Trade Channel Proportions: For cluster 1, 55% of customers are within the "licensed hospitality" channel.  For cluster 5, 46% of customers are within the "comprehensive dining" channel.
#### Sub-Trade Channel Proportions: For cluster 1, 55% of customers belong to the "other large retailer" channel.  For cluster 5, 46% are within the "fraternity" channel.

### Clusters for LMP gallon-only customers with declining orders (AGI Group = 0)
#### Clusters 1 and 8 have the highest (negative) mean AGI values (-30% and -24%).  We will emphasize these clusters in terms of their customer demographics as our "exclusion group".  In other words, these are customers who should be offboarded from the red truck program.  This interpretation is applicable to further analysis of clusters within this AGI group.
#### Frequent Order Type Proportions: For cluster 1, ~55% of customers place orders through "other" means.  For cluster 8, ~84% of customers place orders through sales reps.
#### Cold Drink Channel Proportions: For cluster 1, ~87% of customers are within the dining channel.  For cluster 8, ~81% of customers are also within the dining channel.
#### Trade Channel Proportions: For cluster 1, ~76% of customers are within the "fast casual dining" channel.  For cluster 8, 46% of customers are within the "licensed hospitality" channel.
#### Sub-Trade Channel Proportions: For cluster 1, 36% of customers belong to the "other fast food" channel.  For cluster 8, ~18% are within the "other dining" channel.

### Clusters for all customers with positive growth (AGI Group = 1)
#### Clusters 1 and 4 have the highest AGI values (~67% and ~42%).
#### Frequent Order Type Proportions: For cluster 1, ~70% of customers place orders through sales reps.  For cluster 4, 66% of customers also place orders through sales reps.
#### Cold Drink Channel Proportions: For cluster 1, 69% of customers are within the dining channel.  For cluster 4, 68% of customers are also within the dining channel.
#### Trade Channel Proportions: For cluster 1, 40% of customers are within the "comprehensive dining" channel.  For cluster 4, 53% of customers are within the "fast casual dining" channel.
#### Sub-Trade Channel Proportions: For cluster 1, 40% of customers belong to the "FSR-MISC" channel.  For cluster 4, 17% are within the "Mexican fast food" channel.

### Clusters for all customers with declining orders (AGI Group = 0)
#### Clusters 1 and 4 have the highest (negative) mean AGI values (-13% and -26%).
#### Frequent Order Type Proportions: For cluster 1, 78% of customers place orders through sales reps.  For cluster 4, 72% of customers also place orders through sales reps.
#### Cold Drink Channel Proportions: For cluster 1, 62% of customers are within the event channel.  For cluster 4, 75% of customers are within the dining channel.
#### Trade Channel Proportions: For cluster 1, 53% of customers are within the "outdoor activities" channel.  For cluster 4, 24% of customers are within the "other dining and beverage" channel.
#### Sub-Trade Channel Proportions: For cluster 1, 50% of customers belong to the "other outdoor activities" channel.  For cluster 4, 19% are within the "FSR-MISC" channel.



# K - Prototype Clustering for Customers Ordering Beyond Threshold


```{r}
# Cluster for ALL beyond threshold
g2_op_m_cluster <- g2_m |>
  select(FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL, Has.Primary.Group.Number.,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, MONTHLY_TOTAL) |>
  filter(MONTHLY_TOTAL >= 33.3)

# Scale numerical variables using min-max scaling
#g2_op_m_cluster <- g2_op_m_cluster |>
  #mutate(MONTHLY_TOTAL = (MONTHLY_TOTAL - min(MONTHLY_TOTAL)) / (max(MONTHLY_TOTAL) - min(MONTHLY_TOTAL)))
```

```{r}
wcss <- numeric(15)
for (k in 1:15) {
  kpres <- kproto(g2_op_m_cluster, k)
  wcss[k] <- kpres$tot.withinss
}

# Plot the Elbow graph
plot(1:15, wcss, type = "b", xlab = "Number of Clusters", ylab = "Within-cluster Sum of Squares")
```

```{r}
kpres <- kproto(g2_op_m_cluster, k = 10)

summary(kpres)

g2_op_m_cluster$Cluster <- kpres$cluster
```

```{r}
#summary_output_g2op_m <- capture.output(summary(kpres))


#writeLines(summary_output_g2op_m, "cluster_summary_g2op_m.txt")

# View the first few rows of the data frame
#head(g1_m_cluster)
```

```{r}
# Create boxplot
#ggplot(g2_op_m_cluster, aes(x = factor(Cluster), y = MONTHLY_TOTAL)) +
  #geom_boxplot() +
  #labs(x = "Cluster Number", y = "Monthly Total") +
  #theme_minimal()
```

```{r}
# Cluster for LMP beyond threshold
g1_op_m_cluster <- g1_m |>
  select(FREQUENT_ORDER_TYPE, COLD_DRINK_CHANNEL, Has.Primary.Group.Number.,
         TRADE_CHANNEL, SUB_TRADE_CHANNEL, ORDERED_GALLONS) |>
  filter(ORDERED_GALLONS >= 33.3)

# Scale numerical variables using min-max scaling
#g1_op_m_cluster <- g1_op_m_cluster |>
  #mutate(MONTHLY_TOTAL = (MONTHLY_TOTAL - min(MONTHLY_TOTAL)) / (max(MONTHLY_TOTAL) - min(MONTHLY_TOTAL)))
```

```{r}
wcss <- numeric(15)
for (k in 1:15) {
  kpres <- kproto(g1_op_m_cluster, k)
  wcss[k] <- kpres$tot.withinss
}

# Plot the Elbow graph
plot(1:15, wcss, type = "b", xlab = "Number of Clusters", ylab = "Within-cluster Sum of Squares")
```

```{r}
kpres <- kproto(g1_op_m_cluster, k = 7)

summary(kpres)

g1_op_m_cluster$Cluster <- kpres$cluster
```

```{r}
#summary_output_g1op_m <- capture.output(summary(kpres))


#writeLines(summary_output_g1op_m, "cluster_summary_g1op_m.txt")
```


## Beyond Threshold Cluster Analysis
#### This analysis is for customers who are already exceeding the existing 400 gallon/year threshold.  As such, it is emphasized on monthly order volumes rather than growth index.

### Clusters for all customers beyond the yearly threshold.
#### Clusters 3 and 5 have the highest average monthly orders (1,115 and 539 gallons/month)
#### Frequent Order Type Proportions: For cluster 3, 76% of customers place orders through sales reps.  For cluster 5, 77% of customers also place orders through sales reps.
#### Cold Drink Channel Proportions: For cluster 3, 87% of customers are within the dining channel.  For cluster 5, 95% of customers are within the bulk trade channel.
#### Trade Channel Proportions: For cluster 3, 87% of customers are within the "fast casual dining" channel.  For cluster 5, 83% of customers are within the "general" channel.
#### Sub-Trade Channel Proportions: For cluster 3, 85% of customers belong to the "pizza fast food" channel.  For cluster 5, 82% are within the "comprehensive provider" channel.

### Clusters for LMP gallon-only customers beyond the yearly threshold.
#### Clusters 4 and 7 have the highest average monthly orders (108 and 731 gallons/month)
#### Frequent Order Type Proportions: For cluster 4, 99% of customers place orders through sales reps.  For cluster 7, 79% of customers also place orders through sales reps.
#### Cold Drink Channel Proportions: For cluster 4, 99% of customers are within the dining channel.  For cluster 7, 77% of customers are also within the dining channel.
#### Trade Channel Proportions: For cluster 4, 93% of customers are within the "comprehensive dining" channel.  For cluster 7, 44% of customers are also within the "comprehensive dining" channel.
#### Sub-Trade Channel Proportions: For cluster 4, 93% of customers belong to the "FSR-MISC" channel.  For cluster 4, 44% are also within this channel.



# Density Based Clustering for Customer Yearly Orders 

```{r}
# For LMP yearly orders
g1_y_geo <- aggregate(TOTAL_YEAR_ORDERS ~ LATITUDE + LONGITUDE + AGI_GROUP, data = g1_y, sum)

g1_y_geo <- g1_y_geo |>
  filter(TOTAL_YEAR_ORDERS <= 400)

# Ensure the data is in the correct format
data_matrix <- as.matrix(g1_y_geo[, c("LATITUDE", "LONGITUDE")])

# Set parameters for DBSCAN
eps <- 1 # Maximum distance between two points to be considered in the same neighborhood
minPts <- 10 # Minimum number of points to form a dense region

# Perform DBSCAN clustering
dbscan_result <- dbscan(data_matrix, eps = eps, minPts = minPts)

# Add cluster assignments to the data frame
g1_y_geo$Cluster <- dbscan_result$cluster

```


```{r}
# Convert to spatial data frame
g1_y_zips_sf <- st_as_sf(g1_y_geo, coords = c("LATITUDE", "LONGITUDE"), crs = 4326)
```

```{r}
us_map <- map_data("state")
```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g1_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for LMP Yearly Orders in the US") +
  theme_minimal()

```

### We can see that customer data exists within only 5 states.

```{r}
# Plot for  Kansas customers
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g1_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-102, -94), ylim = c(36, 40)) +  # Adjust these limits as needed
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for LMP Yearly Orders in Kansas") +
  theme_minimal()

```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g1_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-73, -69), ylim = c(41, 43)) +  # Adjusted limits for Massachusetts
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for LMP Yearly Orders in Massachusetts") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g1_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-94, -88), ylim = c(28, 33)) +  # Adjusted limits for Louisiana
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for LMP Yearly Orders in Louisiana") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g1_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-89, -81), ylim = c(36, 39)) +  # Adjusted limits for Kentucky
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for LMP Yearly Orders in Kentucky") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g1_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-79, -75), ylim = c(37, 40)) +  # Adjusted limits for Maryland
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for LMP Yearly Orders in Maryland") +
  theme_minimal()
```

```{r}
# For all yearly orders
g2_y_geo <- aggregate(TOTAL_YEAR_ORDERS ~ LATITUDE + LONGITUDE + AGI_GROUP, data = g2_y, sum)

g2_y_geo <- g2_y_geo |>
  filter(TOTAL_YEAR_ORDERS <= 400)

g2data_matrix <- as.matrix(g2_y_geo[, c("LATITUDE", "LONGITUDE")])

# Set parameters for DBSCAN
g2eps <- 0.5  # Maximum distance between two points to be considered in the same neighborhood
g2minPts <- 5  # Minimum number of points to form a dense region

g2dbscan_result <- dbscan(g2data_matrix, eps = g2eps, minPts = g2minPts)

g2_y_geo$Cluster <- g2dbscan_result$cluster
```



```{r}
g2_y_zips_sf <- st_as_sf(g2_y_geo, coords = c("LATITUDE", "LONGITUDE"), crs = 4326)
```


```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g2_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for All Yearly Orders in the US") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g2_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-102, -94), ylim = c(36, 40)) +  # Adjust these limits as needed
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for All Yearly Orders in Kansas") +
  theme_minimal()

```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g2_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-73, -69), ylim = c(41, 43)) +  # Adjusted limits for Massachusetts
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for All Yearly Orders in Massachusetts") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g2_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-94, -88), ylim = c(28, 33)) +  # Adjusted limits for Louisiana
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for All Yearly Orders in Louisiana") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g2_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-89, -81), ylim = c(36, 39)) +  # Adjusted limits for Kentucky
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for All Yearly Orders in Kentucky") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  geom_sf(data = g2_y_zips_sf, aes(size = TOTAL_YEAR_ORDERS, color = as.factor(AGI_GROUP))) +
  coord_sf(xlim = c(-79, -75), ylim = c(37, 40)) +  # Adjusted limits for Maryland
  labs(color = "AGI Group", size = "Total Year Orders", title = "Clusters for All Yearly Orders in Maryland") +
  theme_minimal()
```


## Density Based Cluster Analysis

#### These clusters are plotted according to geographical locations of customers who are below the 400 gallon threshold.  The plot color indicates customers with positive AGI (blue) and negative AGI (red).  It is anticipated that these plots can be used to segment low yearly volume customers who also show decline in order volume, and decide whether or not it would be logistically efficient to continue serving them via red truck service depending on their relative distance from "hubs" of customers who will most likely continue to be served on the red truck service.  In contrast, customers with both high growth potential and close proximity to each other can be most easily served with the red truck distribution service, and should be considered to be kept on this service.






